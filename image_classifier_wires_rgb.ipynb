{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classifier_maths_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayvictor/imageClassifier/blob/master/image_classifier_wires_rgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbNOeWBhkqv1",
        "colab_type": "code",
        "outputId": "56c1bd97-dd4a-475a-fbbf-e18efab6c588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Activation, Dropout, Flatten, Dense \n",
        "from keras import backend as K \n",
        "\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "train_data_dir = 'drive/My Drive/MATHS_TRAIN_NEW'\n",
        "validation_data_dir = 'drive/My Drive/MATHS_VALIDATION'\n",
        "nb_train_samples = 860\n",
        "nb_validation_samples = 6\n",
        "epochs = 25\n",
        "batch_size = 15\n",
        "\n",
        "input_shape = (img_width, img_height, 3) #Keras Backend is TensorFlow, so image_data_format is channels_last\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n",
        "model.add(Activation('relu')) \n",
        "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
        "\n",
        "model.add(Conv2D(32, (2, 2))) \n",
        "model.add(Activation('relu')) \n",
        "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
        "\n",
        "model.add(Conv2D(32, (2, 2))) \n",
        "model.add(Activation('relu')) \n",
        "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
        "\n",
        "model.add(Conv2D(64, (2, 2))) \n",
        "model.add(Activation('relu')) \n",
        "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
        "\n",
        "model.add(Conv2D(64, (2, 2))) \n",
        "model.add(Activation('relu')) \n",
        "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(64)) \n",
        "model.add(Activation('relu')) \n",
        "model.add(Dropout(0.5)) \n",
        "model.add(Dense(6))   # Change me when more categories are added\n",
        "model.add(Activation('sigmoid')) \n",
        "\n",
        "model.compile(loss ='binary_crossentropy', \n",
        "\t\t\t\t\toptimizer ='rmsprop', \n",
        "\t\t\t\tmetrics =['accuracy']) \n",
        "\n",
        "train_datagen = ImageDataGenerator( \n",
        "\t\t\t\trescale = 1. / 255, \n",
        "\t\t\t\tshear_range = 0.2, \n",
        "\t\t\t\tzoom_range = 0.2, \n",
        "\t\t\thorizontal_flip = True) \n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1. / 255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
        "\t\t\t\t\t\t\ttarget_size =(img_width, img_height), \n",
        "\t\t\t\t\tbatch_size = batch_size, class_mode ='categorical') \n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( \n",
        "\t\t\t\t\t\t\t\t\tvalidation_data_dir, \n",
        "\t\t\t\ttarget_size =(img_width, img_height), \n",
        "\t\tbatch_size = batch_size, class_mode ='categorical') \n",
        "\n",
        "model.fit_generator(train_generator, \n",
        "\tsteps_per_epoch = nb_train_samples // batch_size, \n",
        "\tepochs = epochs, validation_data = validation_generator, \n",
        "\tvalidation_steps = nb_validation_samples // batch_size) \n",
        "\n",
        "model.save_weights('model_saved.h5') \n",
        "\n",
        "model.save('model_new.h5') \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Found 861 images belonging to 6 classes.\n",
            "Found 28 images belonging to 6 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "57/57 [==============================] - 317s 6s/step - loss: 0.5181 - acc: 0.7924 - val_loss: 0.4567 - val_acc: 0.8333\n",
            "Epoch 2/25\n",
            "57/57 [==============================] - 46s 813ms/step - loss: 0.4691 - acc: 0.8178 - val_loss: 0.4049 - val_acc: 0.8333\n",
            "Epoch 3/25\n",
            "57/57 [==============================] - 41s 727ms/step - loss: 0.4169 - acc: 0.8157 - val_loss: 0.3805 - val_acc: 0.8095\n",
            "Epoch 4/25\n",
            "57/57 [==============================] - 42s 734ms/step - loss: 0.3833 - acc: 0.8171 - val_loss: 0.3433 - val_acc: 0.8274\n",
            "Epoch 5/25\n",
            "57/57 [==============================] - 42s 732ms/step - loss: 0.3177 - acc: 0.8442 - val_loss: 0.3478 - val_acc: 0.8333\n",
            "Epoch 6/25\n",
            "57/57 [==============================] - 42s 738ms/step - loss: 0.2728 - acc: 0.8684 - val_loss: 0.3199 - val_acc: 0.8631\n",
            "Epoch 7/25\n",
            "57/57 [==============================] - 42s 733ms/step - loss: 0.2562 - acc: 0.8809 - val_loss: 0.2735 - val_acc: 0.8810\n",
            "Epoch 8/25\n",
            "57/57 [==============================] - 42s 737ms/step - loss: 0.2276 - acc: 0.8966 - val_loss: 0.1895 - val_acc: 0.9286\n",
            "Epoch 9/25\n",
            "57/57 [==============================] - 42s 731ms/step - loss: 0.2141 - acc: 0.9103 - val_loss: 0.1785 - val_acc: 0.9226\n",
            "Epoch 10/25\n",
            "57/57 [==============================] - 42s 738ms/step - loss: 0.1777 - acc: 0.9221 - val_loss: 0.1377 - val_acc: 0.9286\n",
            "Epoch 11/25\n",
            "57/57 [==============================] - 42s 731ms/step - loss: 0.1662 - acc: 0.9288 - val_loss: 0.0677 - val_acc: 0.9821\n",
            "Epoch 12/25\n",
            "57/57 [==============================] - 41s 726ms/step - loss: 0.1356 - acc: 0.9466 - val_loss: 0.0469 - val_acc: 0.9881\n",
            "Epoch 13/25\n",
            "57/57 [==============================] - 42s 730ms/step - loss: 0.1219 - acc: 0.9537 - val_loss: 0.0700 - val_acc: 0.9821\n",
            "Epoch 14/25\n",
            "57/57 [==============================] - 42s 733ms/step - loss: 0.1144 - acc: 0.9563 - val_loss: 0.0188 - val_acc: 1.0000\n",
            "Epoch 15/25\n",
            "57/57 [==============================] - 42s 730ms/step - loss: 0.1144 - acc: 0.9618 - val_loss: 0.0187 - val_acc: 1.0000\n",
            "Epoch 16/25\n",
            "57/57 [==============================] - 42s 743ms/step - loss: 0.0941 - acc: 0.9661 - val_loss: 0.0718 - val_acc: 0.9643\n",
            "Epoch 17/25\n",
            "57/57 [==============================] - 41s 726ms/step - loss: 0.0892 - acc: 0.9639 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 18/25\n",
            "57/57 [==============================] - 42s 734ms/step - loss: 0.0894 - acc: 0.9717 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 19/25\n",
            "57/57 [==============================] - 42s 738ms/step - loss: 0.0898 - acc: 0.9719 - val_loss: 0.0237 - val_acc: 0.9940\n",
            "Epoch 20/25\n",
            "57/57 [==============================] - 42s 742ms/step - loss: 0.0905 - acc: 0.9696 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 21/25\n",
            "57/57 [==============================] - 43s 747ms/step - loss: 0.0598 - acc: 0.9788 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 22/25\n",
            "57/57 [==============================] - 42s 729ms/step - loss: 0.0629 - acc: 0.9795 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 23/25\n",
            "57/57 [==============================] - 42s 737ms/step - loss: 0.0692 - acc: 0.9770 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 24/25\n",
            "57/57 [==============================] - 41s 726ms/step - loss: 0.0719 - acc: 0.9784 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 25/25\n",
            "57/57 [==============================] - 42s 729ms/step - loss: 0.0467 - acc: 0.9826 - val_loss: 0.0037 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a0e7ccef-f838-4104-b88b-79c2b845f6b5",
        "id": "QtFo149YDwWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "# dimensions of our images\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "\n",
        "\n",
        "# load the model we saved\n",
        "model = load_model('model_new.h5')\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "count = 0\n",
        "total_count = 0\n",
        "\n",
        "\n",
        "for item in glob.glob('drive/My Drive/MATHS_TEST/*.jpg'):\n",
        "  total_count = total_count + 1\n",
        "  output = \"UNKNOWN\"\n",
        "\n",
        "\n",
        "  # predicting images\n",
        "  img = image.load_img(item, target_size=(img_width, img_height))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict_classes(images, batch_size=10)\n",
        "\n",
        "\n",
        "  #print the classes, the images belong to\n",
        "  #print(classes)\n",
        "  #print(classes[0])\n",
        "\n",
        "  available_classes = train_generator.class_indices \n",
        "  #print(available_classes)\n",
        "\n",
        "  print(os.path.basename(item).split(\"_\")[0])\n",
        "\n",
        "  if os.path.basename(item).split(\"_\")[0] == \"R\":\n",
        "      output = \"RED\"\n",
        "  elif os.path.basename(item).split(\"_\")[0] == \"G\":\n",
        "      output = \"GREEN\"\n",
        "  elif os.path.basename(item).split(\"_\")[0] == \"B\":\n",
        "      output = \"BLACK\"\n",
        "  elif os.path.basename(item).split(\"_\")[0] == \"GR\":\n",
        "      output = \"GREEN_RED\"\n",
        "  elif os.path.basename(item).split(\"_\")[0] == \"BG\":\n",
        "      output = \"BLACK_GREEN\"\n",
        "  elif os.path.basename(item).split(\"_\")[0] == \"RB\":\n",
        "      output = \"BLACK_RED\"  \n",
        "     \n",
        "  #Add more elifs here...\n",
        "  \n",
        "\n",
        "  if str(list(available_classes.keys())[list(available_classes.values()).index(classes[0])]) == output:\n",
        "    count = count + 1\n",
        "  \n",
        "  \n",
        "  print(\"Original Result: \", output )\n",
        "  print(\"Prediction: \", list(available_classes.keys())[list(available_classes.values()).index(classes[0])], \"\\n\\n\")\n",
        "\n",
        "print(\"Accuracy: \", (count/total_count)*100, \"%\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "G\n",
            "Original Result:  GREEN\n",
            "Prediction:  GREEN \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "G\n",
            "Original Result:  GREEN\n",
            "Prediction:  GREEN \n",
            "\n",
            "\n",
            "G\n",
            "Original Result:  GREEN\n",
            "Prediction:  GREEN \n",
            "\n",
            "\n",
            "BG\n",
            "Original Result:  BLACK_GREEN\n",
            "Prediction:  BLACK_GREEN \n",
            "\n",
            "\n",
            "BG\n",
            "Original Result:  BLACK_GREEN\n",
            "Prediction:  BLACK_GREEN \n",
            "\n",
            "\n",
            "BG\n",
            "Original Result:  BLACK_GREEN\n",
            "Prediction:  BLACK_GREEN \n",
            "\n",
            "\n",
            "BG\n",
            "Original Result:  BLACK_GREEN\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "G\n",
            "Original Result:  GREEN\n",
            "Prediction:  GREEN \n",
            "\n",
            "\n",
            "G\n",
            "Original Result:  GREEN\n",
            "Prediction:  GREEN \n",
            "\n",
            "\n",
            "BG\n",
            "Original Result:  BLACK_GREEN\n",
            "Prediction:  BLACK_GREEN \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  BLACK_RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "RB\n",
            "Original Result:  BLACK_RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "B\n",
            "Original Result:  BLACK\n",
            "Prediction:  BLACK \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "GR\n",
            "Original Result:  GREEN_RED\n",
            "Prediction:  GREEN_RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "R\n",
            "Original Result:  RED\n",
            "Prediction:  RED \n",
            "\n",
            "\n",
            "Accuracy:  84.70588235294117 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty0lIs-EOajY",
        "colab_type": "code",
        "outputId": "5c8d11ac-5079-4d67-8555-854869a8c5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!cat ~/.keras/keras.json\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"epsilon\": 1e-07, \n",
            "    \"floatx\": \"float32\", \n",
            "    \"image_data_format\": \"channels_last\", \n",
            "    \"backend\": \"tensorflow\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BbgWML9GO7Ns"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO_d-fYRP_1x",
        "colab_type": "text"
      },
      "source": [
        "https://keras.io/preprocessing/image/\n",
        "\n",
        "https://www.codesofinterest.com/2017/09/keras-image-data-format.html\n",
        "\n",
        "https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
        "\n"
      ]
    }
  ]
}